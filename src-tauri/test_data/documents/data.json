{
  "project": {
    "name": "Tektra AI Assistant",
    "version": "0.3.0",
    "description": "Multimodal AI assistant with voice, vision, and action capabilities",
    "features": [
      {
        "name": "Voice Interaction",
        "status": "implemented",
        "components": [
          "Whisper STT",
          "Silero VAD",
          "Wake word detection"
        ]
      },
      {
        "name": "Vision Processing",
        "status": "implemented",
        "components": [
          "MobileNet-V5 encoder",
          "Real-time camera feed",
          "Image understanding"
        ]
      },
      {
        "name": "Document RAG",
        "status": "in_progress",
        "components": [
          "PDF processing",
          "Vector search",
          "Context assembly"
        ]
      }
    ],
    "models": {
      "primary": "gemma3n:e4b",
      "context_window": 32000,
      "multimodal": true,
      "capabilities": ["text", "image", "audio"]
    },
    "backends": [
      {
        "name": "enhanced_ollama",
        "type": "inference",
        "status": "active",
        "features": ["streaming", "multimodal", "function_calling"]
      }
    ]
  },
  "test_cases": [
    {
      "id": "TC001",
      "description": "Test document processing with user query",
      "input": {
        "query": "What are the types of machine learning?",
        "document": "sample.txt"
      },
      "expected_output": "Should identify supervised, unsupervised, and reinforcement learning"
    },
    {
      "id": "TC002",
      "description": "Test multimodal input handling",
      "input": {
        "query": "Describe what you see",
        "image": "test_image.png",
        "audio": "test_audio.wav"
      },
      "expected_output": "Should process all modalities and provide coherent response"
    }
  ]
}