[package]
name = "tektra"
version = "0.2.3"
description = "A voice-interactive AI assistant with multimodal capabilities"
authors = ["David Irvine <david.irvine@maidsafe.net>"]
license = "MIT OR Apache-2.0"
repository = "https://github.com/dirvine/tektra"
homepage = "https://github.com/dirvine/tektra"
readme = "../README.md"
keywords = ["ai", "assistant", "voice", "tauri", "gemma"]
categories = ["command-line-utilities", "multimedia::audio"]
edition = "2021"
default-run = "tektra"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[build-dependencies]
tauri-build = { version = "2.0", features = [] }

[dependencies]
tauri = { version = "2.0", features = [] }
tauri-plugin-shell = "2.0"
tauri-plugin-opener = "2.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tokio = { version = "1", features = ["full"] }
uuid = { version = "1.0", features = ["v4"] }

# ML Dependencies for TinyLlama
hf-hub = { version = "0.3", features = ["tokio"] }
anyhow = "1.0"
tracing = "0.1"
tracing-subscriber = "0.3"
reqwest = { version = "0.11", features = ["json", "stream", "blocking"] }
dirs = "5.0"
futures = "0.3"
bytesize = "1.3"
# Audio processing
cpal = "0.15"
hound = "3.5"
# rubato = "0.15"  # For resampling if needed later

# Speech processing
whisper-rs = "0.11"  # For Whisper STT
# ort = "2.0"  # ONNX Runtime for Silero VAD when ready

# Legacy dependencies removed - using Ollama for model management

# Ollama integration for reliable model management
ollama-rs = { version = "0.3.2", features = ["stream", "tokio"] }
ollama_td = "0.4.0"
async-trait = "0.1"
toml = "0.8"
num_cpus = "1.16"


# For downloading models
# (already have hf-hub, reqwest, futures, dirs)

# For camera/video input
nokhwa = { version = "0.10", features = ["input-avfoundation"] }

# For avatar rendering (3D - not needed for 2D canvas)
# wgpu = "0.20"

# For base64 encoding
base64 = "0.22"

# For image encoding
png = "0.17"

# For half precision float handling
half = "2.4"

# Multimodal support dependencies
image = { version = "0.25.2", features = ["jpeg", "png", "gif", "webp", "tiff"] }
symphonia = { version = "0.5.4", features = ["mp3", "aac", "flac", "wav"] }

# Multimodal inference backends
# Note: candle, mistral.rs and llama.cpp have dependency/API issues
# Using enhanced Ollama backend for now which provides good multimodal support
# Future: Add more backends as they become stable

# Video processing (conditionally compiled for platforms that support it)
[target.'cfg(not(target_os = "windows"))'.dependencies]
ffmpeg-next = { version = "7.0.0", optional = true }

# Computer vision and image processing
imageproc = "0.25.0"
nalgebra = "0.33.0"  # Linear algebra for image transformations
rusttype = "0.9.3"  # For text rendering on images

# Document processing dependencies
pdf = "0.9.0"
lopdf = "0.33.0"
docx = "1.1.2"
regex = "1.10.2"
md5 = "0.7.0"
chrono = { version = "0.4", features = ["serde"] }
reqwest = { version = "0.12", features = ["json"] }

# Multimodal data visualization and debugging
# rerun = { version = "0.18.2", optional = true } # Disabled due to wasm-bindgen conflicts

# Test runner dependencies  
clap = { version = "4.5", features = ["derive"], optional = true }
colored = { version = "2.1", optional = true }
dialoguer = { version = "0.11", optional = true }
indicatif = { version = "0.17", optional = true }

# Feature flags for optional components
[features]
default = ["video-processing"]
video-processing = ["ffmpeg-next"]
e2e-testing = ["clap", "colored", "dialoguer", "indicatif"]
# mistral-backend = ["mistralrs"]
# llama-backend = ["llama_cpp"]
# debug-tools = ["rerun"] # Disabled due to wasm-bindgen conflicts
# full-multimodal = ["video-processing", "debug-tools"] # Disabled due to wasm-bindgen conflicts

[[bin]]
name = "tektra"
path = "src/main.rs"

[[bin]]
name = "generate_test_images"
path = "src/bin/generate_test_images.rs"

[[bin]]
name = "e2e-test-runner"
path = "src/bin/e2e_test_runner.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "simple-e2e-test"
path = "src/bin/simple_e2e_test.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "tektra-e2e-test"
path = "src/bin/tektra_e2e_test.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "test-bundled-ollama"
path = "src/bin/test_bundled_ollama.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "demo-inference"
path = "src/bin/demo_inference.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "check-ollama"
path = "src/bin/check_ollama.rs"

[[bin]]
name = "multimodal-test-runner"
path = "src/bin/multimodal_test_runner.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "comprehensive-multimodal-test"
path = "src/bin/comprehensive_multimodal_test.rs"
required-features = ["e2e-testing"]

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true
