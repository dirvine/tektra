[package]
name = "tektra"
version = "0.2.3"
description = "A voice-interactive AI assistant with multimodal capabilities"
authors = ["David Irvine <david.irvine@maidsafe.net>"]
license = "MIT OR Apache-2.0"
repository = "https://github.com/dirvine/tektra"
homepage = "https://github.com/dirvine/tektra"
readme = "../README.md"
keywords = ["ai", "assistant", "voice", "tauri", "gemma"]
categories = ["command-line-utilities", "multimedia::audio"]
edition = "2021"
default-run = "tektra"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[build-dependencies]
tauri-build = { version = "2.0", features = [] }

[dependencies]
tauri = { version = "2.0", features = [] }
tauri-plugin-shell = "2.0"
tauri-plugin-opener = "2.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tokio = { version = "1", features = ["full"] }
uuid = { version = "1.0", features = ["v4"] }

# ML Dependencies for TinyLlama
hf-hub = { version = "0.3", features = ["tokio"] }
anyhow = "1.0"
thiserror = "1.0"
tracing = "0.1"
tracing-subscriber = "0.3"
reqwest = { version = "0.11", features = ["json", "stream", "blocking"] }
dirs = "5.0"
futures = "0.3"
bytesize = "1.3"
# Audio processing
cpal = "0.15"
hound = "3.5"
# rubato = "0.15"  # For resampling if needed later

# Speech processing
whisper-rs = "0.11"  # For Whisper STT
# ort = "2.0"  # ONNX Runtime for Silero VAD when ready

# Legacy Ollama dependencies removed - now using mistral.rs backend
async-trait = "0.1"
toml = "0.8"
num_cpus = "1.16"


# For downloading models
# (already have hf-hub, reqwest, futures, dirs)

# For camera/video input
nokhwa = { version = "0.10", features = ["input-avfoundation"] }

# For avatar rendering (3D - not needed for 2D canvas)
# wgpu = "0.20"

# For base64 encoding
base64 = "0.22"

# For image encoding
png = "0.17"

# For half precision float handling
half = "2.4"

# Multimodal support dependencies
image = { version = "0.25.2", features = ["jpeg", "png", "gif", "webp", "tiff"] }
symphonia = { version = "0.5.4", features = ["mp3", "aac", "flac", "wav"] }

# Primary inference backend: mistral.rs for production multimodal AI
# Temporarily disabled due to tokenizer compatibility issues - will re-enable after resolving
# mistralrs = { git = "https://github.com/EricLBuehler/mistral.rs.git", rev = "68c078f7630b61469d4c8e391dc05da334c60291", default-features = false, features = ["metal"] }
# Pin tokenizer version to match mistral.rs compatibility
# tokenizers = "=0.20.4"
# candle dependencies managed by mistral.rs
# candle-core = { version = "0.8", features = ["metal"] }
# candle-nn = { version = "0.8", features = ["metal"] }
# candle-transformers = { version = "0.8", features = ["metal"] }
# tokenizers managed by mistral.rs
tokio-stream = "0.1.15"
parking_lot = "0.12"
accelerate-src = "0.3"
safetensors = "0.4"
async-stream = "0.3"

# Candle dependencies are included from mistral.rs
# Note: Using mistral.rs's forked candle version for compatibility

# Enhanced MCP support
# mcp-rust = { version = "0.1", optional = true }  # To be added when available
jsonrpc = "0.18"

# Voice integration with Unmute
tokio-tungstenite = { version = "0.24", features = ["native-tls"] }
futures-util = "0.3"
url = "2.5"
opus = "0.3"

# Image processing for vision features
imageproc = "0.25"

# Video processing (conditionally compiled for platforms that support it)
[target.'cfg(not(target_os = "windows"))'.dependencies]
ffmpeg-next = { version = "7.0.0", optional = true }

# Computer vision and image processing
imageproc = "0.25.0"
nalgebra = "0.33.0"  # Linear algebra for image transformations
rusttype = "0.9.3"  # For text rendering on images

# Document processing dependencies
pdf = "0.9.0"
lopdf = "0.33.0"
docx = "1.1.2"
regex = "1.10.2"
md5 = "0.7.0"
chrono = { version = "0.4", features = ["serde"] }
reqwest = { version = "0.12", features = ["json"] }

# Multimodal data visualization and debugging
# rerun = { version = "0.18.2", optional = true } # Disabled due to wasm-bindgen conflicts

# Test runner dependencies  
clap = { version = "4.5", features = ["derive"], optional = true }
colored = { version = "2.1", optional = true }
dialoguer = { version = "0.11", optional = true }
indicatif = { version = "0.17", optional = true }

# Feature flags for optional components
[features]
default = ["metal", "video-processing"]
metal = []
cuda = []
video-processing = ["ffmpeg-next"]
mcp-server = []  # Will include mcp-rust when available
e2e-testing = ["clap", "colored", "dialoguer", "indicatif"]
full-multimodal = ["metal", "video-processing", "mcp-server"]

[[bin]]
name = "tektra"
path = "src/main.rs"

[[bin]]
name = "generate_test_images"
path = "src/bin/generate_test_images.rs"

[[bin]]
name = "e2e-test-runner"
path = "src/bin/e2e_test_runner.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "simple-e2e-test"
path = "src/bin/simple_e2e_test.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "tektra-e2e-test"
path = "src/bin/tektra_e2e_test.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "demo-inference"
path = "src/bin/demo_inference.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "multimodal-test-runner"
path = "src/bin/multimodal_test_runner.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "comprehensive-multimodal-test"
path = "src/bin/comprehensive_multimodal_test.rs"
required-features = ["e2e-testing"]

[[bin]]
name = "test-qwen-omni"
path = "src/bin/test_qwen_omni.rs"
required-features = ["e2e-testing"] # Temporarily disabled due to mistral.rs dependency

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true
